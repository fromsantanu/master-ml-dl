# â­ **Lesson 13: Train/Test Split**

### *Explained in very simple, everyday language*

When we build a Machine Learning model, we must make sure it **learns properly** and also **works well on new, unseen data**.

To do this, we divide our dataset into two parts:

1. **Training Set**
2. **Testing Set**

This is called a **Train/Test Split**.

Letâ€™s understand this in the simplest way possible.

---

# ğŸ’ **1. Why do we need a train/test split?**

Imagine you are preparing for an exam.

* You **study** using your notebook and practice questions.
* But in the actual exam, you get **new** questions.

If you only test yourself with the same questions you practiced,
you wonâ€™t know whether you truly learned the concept.

Machine Learning is exactly the same.

We give the model:

ğŸ‘‰ some data to learn from (train set), and
ğŸ‘‰ some data for the final exam (test set).

---

# ğŸ§  **2. What is the Training Set?**

The **training set** is the portion of data used to **teach** the model.

The model learns patterns from it.

### âœ” Example

If we have 1000 rows of data:

* We may use **800 rows** to train the model.

During training, the model sees:

* the features
* the labels (correct answers)
* how they are related

This is like a student practicing many problems.

---

# ğŸ“ **3. What is the Testing Set?**

The **testing set** is a separate portion of data used to **evaluate** the model.

We never show this data to the model during training.

### âœ” Example

From 1000 rows:

* We use the remaining **200 rows** to test the model.

This tests:

* How well the model learned
* Whether it can handle new, unseen data
* Whether it is overfitting or underfitting

This is like giving a student a new question paper after study.

---

# ğŸ“Š **4. Typical split ratios**

Most common splits:

* **80% train, 20% test**
* **70% train, 30% test**
* **75% train, 25% test**

Any ratio is fine as long as:

* Training set is large
* Test set is big enough to judge performance

---

# ğŸ‘“ **5. Simple analogy: Cooking practice**

Imagine you want to learn cooking.

* You practice cooking with **your own ingredients** (training set).
* Someone gives you a **new set of ingredients** to test if you can really cook (test set).

This checks real learning.

---

# âš ï¸ **6. Why not train and test on the same data?**

Because the model will get perfect marks â€” but only because it **memorized** the answers!

This is called **overfitting** (model becomes like a student who memorizes instead of learning).

Using separate test data helps us check:

* Does it truly understand patterns?
* Or did it just memorize the training set?

---

# ğŸ“˜ **7. How Python does it (concept, not code)**

Python has a simple function:

```
train_test_split()
```

This automatically:

* shuffles the data
* splits into train and test
* keeps randomness balanced

We don't need to memorize the code;
just understand **why** we split the data.

---

# ğŸ¯ **8. What happens after splitting?**

After splitting, we follow this flow:

1. Train ML model using **training set**
2. Make predictions on the **test set**
3. Compare predictions with **actual answers**
4. Calculate accuracy, error, and performance

This tells us if the model is ready for real-world use.

---

# ğŸŒŸ **Final takeaway**

Train/Test Split is one of the most important steps in ML.

* **Training set** â†’ the model learns
* **Test set** â†’ we check how well the model learned
* We usually split into **80/20** or **70/30**
* Testing on unseen data gives a **realistic** performance score

Without a proper train/test split, we cannot trust our ML model.

---

