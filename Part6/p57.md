# **Lesson 57: Building Your First ANN**

*Explained in very simple, everyday language.*

---

An **Artificial Neural Network (ANN)** may sound complicated,
but building a simple one is actually like arranging a few blocks in order.

Think of it as building a small team of workers:

* Some workers take input
* Some workers sit in the middle and process it
* One worker gives the final answer

Letâ€™s learn step-by-step.

---

## ğŸ§© **What is an ANN made of?**

A basic ANN has three main parts:

### **1ï¸âƒ£ Input Layer**

This is where data enters.
For example, if you want to predict the price of a house using 3 features:

* Size
* Number of rooms
* Age of house

Then the input layer has **3 neurons**, one for each feature.

---

### **2ï¸âƒ£ Hidden Layers**

These are the workers who think.
They combine information, look for patterns, and pass it forward.

You can have:

* 1 hidden layer (simple models)
* Many hidden layers (deep networks)

For now, we will use just **one**, to keep things easy.

---

### **3ï¸âƒ£ Output Layer**

This gives the final result.

Examples:

* If predicting house price â†’ 1 value
* If classifying an image as cat or dog â†’ 1 neuron (0 or 1)
* If picking between 3 classes â†’ 3 neurons (one for each class)

---

## ğŸ—ï¸ **Steps to Build a Simple ANN (Very Easy Explanation)**

### **Step 1: Choose your input data**

Example: house price prediction with three features.
So we have **3 inputs**.

### **Step 2: Create the input layer**

Just imagine 3 circles (neurons).

### **Step 3: Add a hidden layer**

Letâ€™s add, say, **4 neurons** in the hidden layer.
These neurons learn patterns like:

* Larger houses â†’ higher price
* Newer houses â†’ slightly higher price
* More rooms â†’ more expensive

### **Step 4: Add the output layer**

For one prediction (price), we use **1 neuron**.

So structure becomes:

```
Input (3) â†’ Hidden (4) â†’ Output (1)
```

This is your **first basic ANN**.

---

## âš™ï¸ **What happens inside the ANN?** (Simple Version)

Each neuron:

1. Takes numbers from previous layer
2. Multiplies them with **weights** (importance)
3. Adds a **bias**
4. Applies an **activation function** to make learning smooth
5. Passes the result forward

You donâ€™t need to know math here â€”
just think of it like mixing ingredients in a bowl:

* Some ingredients matter more (weights)
* A little extra seasoning (bias)
* Then you cook it (activation function)
* Finally, you pass it to the next bowl

---

## ğŸ“˜ **How ANN Learns**

The network guesses.
It checks if the guess is wrong.
Then it uses **backpropagation** (previous lesson) to correct itself.

This cycle runs many times until the network becomes good.

---

## ğŸ§  **Very Simple Code Example (Just to See the Shape)**

No need to understand code deeply â€” just observe the structure.

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

model = Sequential()
model.add(Dense(4, activation='relu', input_shape=(3,)))
model.add(Dense(1))

model.compile(optimizer='adam', loss='mse')
model.summary()
```

This creates:

* 3 input values
* 4 hidden neurons
* 1 output neuron

Exactly what we learned.

---

## ğŸ’¡ **One-Line Summary**

Your first ANN is just a simple chain of layers:
**Input â†’ Hidden â†’ Output**,
where each layer learns patterns and improves over time.

---

Would you like **Lesson 58: Batch size, epochs, learning rate** next?

